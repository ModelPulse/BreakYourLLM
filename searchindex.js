Search.setIndex({"alltitles": {"API Documentation:": [[22, null]], "API Reference": [[2, null]], "Attributes": [[1, "attributes"], [4, "attributes"], [7, "attributes"], [20, "attributes"]], "BreakYourLLM documentation": [[22, null]], "Classes": [[0, "classes"], [1, "classes"], [3, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [20, "classes"], [21, "classes"]], "Codebase Organization": [[22, "codebase-organization"]], "Contributing": [[22, "contributing"]], "Features": [[22, "features"]], "Functions": [[4, "functions"], [5, "functions"], [8, "functions"], [9, "functions"]], "Installation": [[22, "installation"]], "Module Contents": [[0, "module-contents"], [1, "module-contents"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"], [7, "module-contents"], [8, "module-contents"], [9, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [20, "module-contents"], [21, "module-contents"]], "Overview": [[22, "overview"]], "Submodules": [[6, "submodules"], [10, "submodules"], [15, "submodules"], [19, "submodules"]], "Table of Contents": [[22, "table-of-contents"]], "Technologies": [[22, "technologies"]], "Test & Simulate your Production LLMs": [[22, "test-simulate-your-production-llms"]], "Usage": [[22, "usage"]], "common_interface": [[0, null]], "execute_tests": [[1, null]], "metadata": [[3, null]], "sources": [[10, null]], "sources.execute_tests": [[4, null]], "sources.full_pipeline": [[5, null]], "sources.helpers": [[6, null]], "sources.helpers.openai_client": [[7, null]], "sources.helpers.paraphrase_helper": [[8, null]], "sources.helpers.testcase_evaluator": [[9, null]], "sources.metrics": [[15, null]], "sources.metrics.accuracy": [[11, null]], "sources.metrics.base_metric": [[12, null]], "sources.metrics.general_stats": [[13, null]], "sources.metrics.hallucination_rate": [[14, null]], "sources.metrics.llm_drift_rate": [[16, null]], "sources.views": [[19, null]], "sources.views.base_view": [[17, null]], "sources.views.incorrect_responses": [[18, null]], "unit_tests": [[20, null]], "unit_tests_result": [[21, null]]}, "docnames": ["autoapi/common_interface/index", "autoapi/execute_tests/index", "autoapi/index", "autoapi/metadata/index", "autoapi/sources/execute_tests/index", "autoapi/sources/full_pipeline/index", "autoapi/sources/helpers/index", "autoapi/sources/helpers/openai_client/index", "autoapi/sources/helpers/paraphrase_helper/index", "autoapi/sources/helpers/testcase_evaluator/index", "autoapi/sources/index", "autoapi/sources/metrics/accuracy/index", "autoapi/sources/metrics/base_metric/index", "autoapi/sources/metrics/general_stats/index", "autoapi/sources/metrics/hallucination_rate/index", "autoapi/sources/metrics/index", "autoapi/sources/metrics/llm_drift_rate/index", "autoapi/sources/views/base_view/index", "autoapi/sources/views/incorrect_responses/index", "autoapi/sources/views/index", "autoapi/unit_tests/index", "autoapi/unit_tests_result/index", "index"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["autoapi/common_interface/index.rst", "autoapi/execute_tests/index.rst", "autoapi/index.rst", "autoapi/metadata/index.rst", "autoapi/sources/execute_tests/index.rst", "autoapi/sources/full_pipeline/index.rst", "autoapi/sources/helpers/index.rst", "autoapi/sources/helpers/openai_client/index.rst", "autoapi/sources/helpers/paraphrase_helper/index.rst", "autoapi/sources/helpers/testcase_evaluator/index.rst", "autoapi/sources/index.rst", "autoapi/sources/metrics/accuracy/index.rst", "autoapi/sources/metrics/base_metric/index.rst", "autoapi/sources/metrics/general_stats/index.rst", "autoapi/sources/metrics/hallucination_rate/index.rst", "autoapi/sources/metrics/index.rst", "autoapi/sources/metrics/llm_drift_rate/index.rst", "autoapi/sources/views/base_view/index.rst", "autoapi/sources/views/incorrect_responses/index.rst", "autoapi/sources/views/index.rst", "autoapi/unit_tests/index.rst", "autoapi/unit_tests_result/index.rst", "index.md"], "indexentries": {"__iter__() (unit_tests.unittest method)": [[20, "unit_tests.UnitTest.__iter__", false]], "__iter__() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.__iter__", false]], "accuracy (class in sources.metrics.accuracy)": [[11, "sources.metrics.accuracy.Accuracy", false]], "answer (unit_tests_result.executionresult attribute)": [[21, "unit_tests_result.ExecutionResult.answer", false]], "atomictestcaseexecutionresult (class in unit_tests_result)": [[21, "unit_tests_result.AtomicTestCaseExecutionResult", false]], "atomicunittest (class in unit_tests)": [[20, "unit_tests.AtomicUnitTest", false]], "basemetric (class in sources.metrics.base_metric)": [[12, "sources.metrics.base_metric.BaseMetric", false]], "basetest (class in common_interface)": [[0, "common_interface.BaseTest", false]], "baseview (class in sources.views.base_view)": [[17, "sources.views.base_view.BaseView", false]], "call_llm_api() (execute_tests.llmexecutor method)": [[1, "execute_tests.LLMExecutor.call_llm_api", false]], "client (in module sources.execute_tests)": [[4, "sources.execute_tests.client", false]], "common_interface": [[0, "module-common_interface", false]], "deep_format() (execute_tests.llmexecutor method)": [[1, "execute_tests.LLMExecutor.deep_format", false]], "description (metadata.metadata attribute)": [[3, "metadata.MetaData.description", false]], "evaluate_answer_for_test() (in module sources.helpers.testcase_evaluator)": [[9, "sources.helpers.testcase_evaluator.evaluate_answer_for_test", false]], "evaluate_responses() (unit_tests.unittest method)": [[20, "unit_tests.UnitTest.evaluate_responses", false]], "evaluate_responses() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.evaluate_responses", false]], "evaluate_responses() (unit_tests_result.executionresult method)": [[21, "unit_tests_result.ExecutionResult.evaluate_responses", false]], "evaluate_responses() (unit_tests_result.paraphrasedquestion method)": [[21, "unit_tests_result.ParaphrasedQuestion.evaluate_responses", false]], "evaluate_test_case() (in module sources.execute_tests)": [[4, "sources.execute_tests.evaluate_test_case", false]], "execute() (unit_tests.unittest method)": [[20, "unit_tests.UnitTest.execute", false]], "execute() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.execute", false]], "execute() (unit_tests_result.paraphrasedquestion method)": [[21, "unit_tests_result.ParaphrasedQuestion.execute", false]], "execute_endpoint() (in module sources.execute_tests)": [[4, "sources.execute_tests.execute_endpoint", false]], "execute_tests": [[1, "module-execute_tests", false]], "execution_result (unit_tests_result.paraphrasedquestion attribute)": [[21, "unit_tests_result.ParaphrasedQuestion.execution_result", false]], "executionresult (class in unit_tests_result)": [[21, "unit_tests_result.ExecutionResult", false]], "executor (in module execute_tests)": [[1, "execute_tests.executor", false]], "extract_answer() (execute_tests.llmexecutor method)": [[1, "execute_tests.LLMExecutor.extract_answer", false]], "file (unit_tests.unittests attribute)": [[20, "unit_tests.UnitTests.file", false]], "from_dict() (common_interface.basetest class method)": [[0, "common_interface.BaseTest.from_dict", false]], "from_json() (common_interface.basetest class method)": [[0, "common_interface.BaseTest.from_json", false]], "generalstats (class in sources.metrics.general_stats)": [[13, "sources.metrics.general_stats.GeneralStats", false]], "generate_tests() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.generate_tests", false]], "generate_unit_tests() (unit_tests.unittest method)": [[20, "unit_tests.UnitTest.generate_unit_tests", false]], "get_evaluation_result_as_numpy() (unit_tests.unittest method)": [[20, "unit_tests.UnitTest.get_evaluation_result_as_numpy", false]], "get_evaluation_result_as_numpy() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.get_evaluation_result_as_numpy", false]], "get_evaluation_result_as_numpy() (unit_tests_result.executionresult method)": [[21, "unit_tests_result.ExecutionResult.get_evaluation_result_as_numpy", false]], "get_evaluation_result_as_numpy() (unit_tests_result.paraphrasedquestion method)": [[21, "unit_tests_result.ParaphrasedQuestion.get_evaluation_result_as_numpy", false]], "get_metric_value() (sources.metrics.accuracy.accuracy method)": [[11, "sources.metrics.accuracy.Accuracy.get_metric_value", false]], "get_metric_value() (sources.metrics.general_stats.generalstats method)": [[13, "sources.metrics.general_stats.GeneralStats.get_metric_value", false]], "get_metric_value() (sources.metrics.hallucination_rate.hallucinationrate method)": [[14, "sources.metrics.hallucination_rate.HallucinationRate.get_metric_value", false]], "get_metric_value() (sources.metrics.llm_drift_rate.llmdriftrate method)": [[16, "sources.metrics.llm_drift_rate.LLMDriftRate.get_metric_value", false]], "guideline (unit_tests.unittest attribute)": [[20, "unit_tests.UnitTest.guideline", false]], "hallucinationrate (class in sources.metrics.hallucination_rate)": [[14, "sources.metrics.hallucination_rate.HallucinationRate", false]], "incorrectresponses (class in sources.views.incorrect_responses)": [[18, "sources.views.incorrect_responses.IncorrectResponses", false]], "json() (sources.views.incorrect_responses.incorrectresponses method)": [[18, "sources.views.incorrect_responses.IncorrectResponses.json", false]], "llmdriftrate (class in sources.metrics.llm_drift_rate)": [[16, "sources.metrics.llm_drift_rate.LLMDriftRate", false]], "llmexecutor (class in execute_tests)": [[1, "execute_tests.LLMExecutor", false]], "load_config() (execute_tests.llmexecutor method)": [[1, "execute_tests.LLMExecutor.load_config", false]], "metadata": [[3, "module-metadata", false]], "metadata (class in metadata)": [[3, "metadata.MetaData", false]], "metadata (unit_tests.unittests attribute)": [[20, "unit_tests.UnitTests.metadata", false]], "metric_result (sources.metrics.accuracy.accuracy attribute)": [[11, "sources.metrics.accuracy.Accuracy.metric_result", false]], "metric_result (sources.metrics.base_metric.basemetric attribute)": [[12, "sources.metrics.base_metric.BaseMetric.metric_result", false]], "metric_result (sources.metrics.general_stats.generalstats attribute)": [[13, "sources.metrics.general_stats.GeneralStats.metric_result", false]], "metric_result (sources.metrics.hallucination_rate.hallucinationrate attribute)": [[14, "sources.metrics.hallucination_rate.HallucinationRate.metric_result", false]], "metric_result (sources.metrics.llm_drift_rate.llmdriftrate attribute)": [[16, "sources.metrics.llm_drift_rate.LLMDriftRate.metric_result", false]], "metric_result_question_test_wise (sources.metrics.accuracy.accuracy attribute)": [[11, "sources.metrics.accuracy.Accuracy.metric_result_question_test_wise", false]], "metric_result_question_wise (sources.metrics.accuracy.accuracy attribute)": [[11, "sources.metrics.accuracy.Accuracy.metric_result_question_wise", false]], "metrics (unit_tests.unittests attribute)": [[20, "unit_tests.UnitTests.metrics", false]], "model (in module unit_tests)": [[20, "unit_tests.MODEL", false]], "module": [[0, "module-common_interface", false], [1, "module-execute_tests", false], [3, "module-metadata", false], [4, "module-sources.execute_tests", false], [5, "module-sources.full_pipeline", false], [6, "module-sources.helpers", false], [7, "module-sources.helpers.openai_client", false], [8, "module-sources.helpers.paraphrase_helper", false], [9, "module-sources.helpers.testcase_evaluator", false], [10, "module-sources", false], [11, "module-sources.metrics.accuracy", false], [12, "module-sources.metrics.base_metric", false], [13, "module-sources.metrics.general_stats", false], [14, "module-sources.metrics.hallucination_rate", false], [15, "module-sources.metrics", false], [16, "module-sources.metrics.llm_drift_rate", false], [17, "module-sources.views.base_view", false], [18, "module-sources.views.incorrect_responses", false], [19, "module-sources.views", false], [20, "module-unit_tests", false], [21, "module-unit_tests_result", false]], "name (metadata.metadata attribute)": [[3, "metadata.MetaData.name", false]], "openai_client (in module sources.helpers.openai_client)": [[7, "sources.helpers.openai_client.openai_client", false]], "paraphrase() (unit_tests.unittest method)": [[20, "unit_tests.UnitTest.paraphrase", false]], "paraphrase() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.paraphrase", false]], "paraphrase_question() (in module sources.execute_tests)": [[4, "sources.execute_tests.paraphrase_question", false]], "paraphrase_question() (in module sources.helpers.paraphrase_helper)": [[8, "sources.helpers.paraphrase_helper.paraphrase_question", false]], "paraphrased_question (unit_tests.unittest attribute)": [[20, "unit_tests.UnitTest.paraphrased_question", false]], "paraphrasedquestion (class in unit_tests_result)": [[21, "unit_tests_result.ParaphrasedQuestion", false]], "parse_response_path() (execute_tests.llmexecutor method)": [[1, "execute_tests.LLMExecutor.parse_response_path", false]], "passed (unit_tests_result.atomictestcaseexecutionresult attribute)": [[21, "unit_tests_result.AtomicTestCaseExecutionResult.passed", false]], "passed() (sources.metrics.accuracy.accuracy method)": [[11, "sources.metrics.accuracy.Accuracy.passed", false]], "passed() (sources.metrics.base_metric.basemetric method)": [[12, "sources.metrics.base_metric.BaseMetric.passed", false]], "passed() (sources.metrics.general_stats.generalstats method)": [[13, "sources.metrics.general_stats.GeneralStats.passed", false]], "passed() (sources.metrics.hallucination_rate.hallucinationrate method)": [[14, "sources.metrics.hallucination_rate.HallucinationRate.passed", false]], "passed() (sources.metrics.llm_drift_rate.llmdriftrate method)": [[16, "sources.metrics.llm_drift_rate.LLMDriftRate.passed", false]], "question (unit_tests.unittest attribute)": [[20, "unit_tests.UnitTest.question", false]], "question (unit_tests_result.paraphrasedquestion attribute)": [[21, "unit_tests_result.ParaphrasedQuestion.question", false]], "read_file() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.read_file", false]], "reason (unit_tests_result.atomictestcaseexecutionresult attribute)": [[21, "unit_tests_result.AtomicTestCaseExecutionResult.reason", false]], "results (sources.views.incorrect_responses.incorrectresponses attribute)": [[18, "sources.views.incorrect_responses.IncorrectResponses.results", false]], "run_by (metadata.metadata attribute)": [[3, "metadata.MetaData.run_by", false]], "run_date (metadata.metadata attribute)": [[3, "metadata.MetaData.run_date", false]], "run_duration (metadata.metadata attribute)": [[3, "metadata.MetaData.run_duration", false]], "run_pipeline() (in module sources.full_pipeline)": [[5, "sources.full_pipeline.run_pipeline", false]], "run_time (metadata.metadata attribute)": [[3, "metadata.MetaData.run_time", false]], "sources": [[10, "module-sources", false]], "sources.execute_tests": [[4, "module-sources.execute_tests", false]], "sources.full_pipeline": [[5, "module-sources.full_pipeline", false]], "sources.helpers": [[6, "module-sources.helpers", false]], "sources.helpers.openai_client": [[7, "module-sources.helpers.openai_client", false]], "sources.helpers.paraphrase_helper": [[8, "module-sources.helpers.paraphrase_helper", false]], "sources.helpers.testcase_evaluator": [[9, "module-sources.helpers.testcase_evaluator", false]], "sources.metrics": [[15, "module-sources.metrics", false]], "sources.metrics.accuracy": [[11, "module-sources.metrics.accuracy", false]], "sources.metrics.base_metric": [[12, "module-sources.metrics.base_metric", false]], "sources.metrics.general_stats": [[13, "module-sources.metrics.general_stats", false]], "sources.metrics.hallucination_rate": [[14, "module-sources.metrics.hallucination_rate", false]], "sources.metrics.llm_drift_rate": [[16, "module-sources.metrics.llm_drift_rate", false]], "sources.views": [[19, "module-sources.views", false]], "sources.views.base_view": [[17, "module-sources.views.base_view", false]], "sources.views.incorrect_responses": [[18, "module-sources.views.incorrect_responses", false]], "test_case (unit_tests.atomicunittest attribute)": [[20, "unit_tests.AtomicUnitTest.test_case", false]], "test_case (unit_tests_result.atomictestcaseexecutionresult attribute)": [[21, "unit_tests_result.AtomicTestCaseExecutionResult.test_case", false]], "test_cases (unit_tests.unittest attribute)": [[20, "unit_tests.UnitTest.test_cases", false]], "test_cases (unit_tests_result.executionresult attribute)": [[21, "unit_tests_result.ExecutionResult.test_cases", false]], "tests() (unit_tests.unittests method)": [[20, "unit_tests.UnitTests.tests", false]], "threshold (sources.metrics.accuracy.accuracy attribute)": [[11, "sources.metrics.accuracy.Accuracy.threshold", false]], "threshold (sources.metrics.base_metric.basemetric attribute)": [[12, "sources.metrics.base_metric.BaseMetric.threshold", false]], "threshold (sources.metrics.general_stats.generalstats attribute)": [[13, "sources.metrics.general_stats.GeneralStats.threshold", false]], "threshold (sources.metrics.hallucination_rate.hallucinationrate attribute)": [[14, "sources.metrics.hallucination_rate.HallucinationRate.threshold", false]], "threshold (sources.metrics.llm_drift_rate.llmdriftrate attribute)": [[16, "sources.metrics.llm_drift_rate.LLMDriftRate.threshold", false]], "to_dict() (common_interface.basetest method)": [[0, "common_interface.BaseTest.to_dict", false]], "to_json() (common_interface.basetest method)": [[0, "common_interface.BaseTest.to_json", false]], "unit_tests": [[20, "module-unit_tests", false]], "unit_tests (unit_tests.unittests attribute)": [[20, "unit_tests.UnitTests.unit_tests", false]], "unit_tests_result": [[21, "module-unit_tests_result", false]], "unittest (class in unit_tests)": [[20, "unit_tests.UnitTest", false]], "unittests (class in unit_tests)": [[20, "unit_tests.UnitTests", false]], "uuid (metadata.metadata attribute)": [[3, "metadata.MetaData.uuid", false]]}, "objects": {"": [[0, 0, 0, "-", "common_interface"], [1, 0, 0, "-", "execute_tests"], [3, 0, 0, "-", "metadata"], [10, 0, 0, "-", "sources"], [20, 0, 0, "-", "unit_tests"], [21, 0, 0, "-", "unit_tests_result"]], "common_interface": [[0, 1, 1, "", "BaseTest"]], "common_interface.BaseTest": [[0, 2, 1, "", "from_dict"], [0, 2, 1, "", "from_json"], [0, 2, 1, "", "to_dict"], [0, 2, 1, "", "to_json"]], "execute_tests": [[1, 1, 1, "", "LLMExecutor"], [1, 3, 1, "", "executor"]], "execute_tests.LLMExecutor": [[1, 2, 1, "", "call_llm_api"], [1, 2, 1, "", "deep_format"], [1, 2, 1, "", "extract_answer"], [1, 2, 1, "", "load_config"], [1, 2, 1, "", "parse_response_path"]], "metadata": [[3, 1, 1, "", "MetaData"]], "metadata.MetaData": [[3, 4, 1, "", "description"], [3, 4, 1, "", "name"], [3, 4, 1, "", "run_by"], [3, 4, 1, "", "run_date"], [3, 4, 1, "", "run_duration"], [3, 4, 1, "", "run_time"], [3, 4, 1, "", "uuid"]], "sources": [[4, 0, 0, "-", "execute_tests"], [5, 0, 0, "-", "full_pipeline"], [6, 0, 0, "-", "helpers"], [15, 0, 0, "-", "metrics"], [19, 0, 0, "-", "views"]], "sources.execute_tests": [[4, 3, 1, "", "client"], [4, 5, 1, "", "evaluate_test_case"], [4, 5, 1, "", "execute_endpoint"], [4, 5, 1, "", "paraphrase_question"]], "sources.full_pipeline": [[5, 5, 1, "", "run_pipeline"]], "sources.helpers": [[7, 0, 0, "-", "openai_client"], [8, 0, 0, "-", "paraphrase_helper"], [9, 0, 0, "-", "testcase_evaluator"]], "sources.helpers.openai_client": [[7, 3, 1, "", "openai_client"]], "sources.helpers.paraphrase_helper": [[8, 5, 1, "", "paraphrase_question"]], "sources.helpers.testcase_evaluator": [[9, 5, 1, "", "evaluate_answer_for_test"]], "sources.metrics": [[11, 0, 0, "-", "accuracy"], [12, 0, 0, "-", "base_metric"], [13, 0, 0, "-", "general_stats"], [14, 0, 0, "-", "hallucination_rate"], [16, 0, 0, "-", "llm_drift_rate"]], "sources.metrics.accuracy": [[11, 1, 1, "", "Accuracy"]], "sources.metrics.accuracy.Accuracy": [[11, 2, 1, "", "get_metric_value"], [11, 4, 1, "", "metric_result"], [11, 4, 1, "", "metric_result_question_test_wise"], [11, 4, 1, "", "metric_result_question_wise"], [11, 2, 1, "", "passed"], [11, 4, 1, "", "threshold"]], "sources.metrics.base_metric": [[12, 1, 1, "", "BaseMetric"]], "sources.metrics.base_metric.BaseMetric": [[12, 4, 1, "", "metric_result"], [12, 2, 1, "", "passed"], [12, 4, 1, "", "threshold"]], "sources.metrics.general_stats": [[13, 1, 1, "", "GeneralStats"]], "sources.metrics.general_stats.GeneralStats": [[13, 2, 1, "", "get_metric_value"], [13, 4, 1, "", "metric_result"], [13, 2, 1, "", "passed"], [13, 4, 1, "", "threshold"]], "sources.metrics.hallucination_rate": [[14, 1, 1, "", "HallucinationRate"]], "sources.metrics.hallucination_rate.HallucinationRate": [[14, 2, 1, "", "get_metric_value"], [14, 4, 1, "", "metric_result"], [14, 2, 1, "", "passed"], [14, 4, 1, "", "threshold"]], "sources.metrics.llm_drift_rate": [[16, 1, 1, "", "LLMDriftRate"]], "sources.metrics.llm_drift_rate.LLMDriftRate": [[16, 2, 1, "", "get_metric_value"], [16, 4, 1, "", "metric_result"], [16, 2, 1, "", "passed"], [16, 4, 1, "", "threshold"]], "sources.views": [[17, 0, 0, "-", "base_view"], [18, 0, 0, "-", "incorrect_responses"]], "sources.views.base_view": [[17, 1, 1, "", "BaseView"]], "sources.views.incorrect_responses": [[18, 1, 1, "", "IncorrectResponses"]], "sources.views.incorrect_responses.IncorrectResponses": [[18, 2, 1, "", "json"], [18, 4, 1, "", "results"]], "unit_tests": [[20, 1, 1, "", "AtomicUnitTest"], [20, 3, 1, "", "MODEL"], [20, 1, 1, "", "UnitTest"], [20, 1, 1, "", "UnitTests"]], "unit_tests.AtomicUnitTest": [[20, 4, 1, "", "test_case"]], "unit_tests.UnitTest": [[20, 2, 1, "", "__iter__"], [20, 2, 1, "", "evaluate_responses"], [20, 2, 1, "", "execute"], [20, 2, 1, "", "generate_unit_tests"], [20, 2, 1, "", "get_evaluation_result_as_numpy"], [20, 4, 1, "", "guideline"], [20, 2, 1, "", "paraphrase"], [20, 4, 1, "", "paraphrased_question"], [20, 4, 1, "", "question"], [20, 4, 1, "", "test_cases"]], "unit_tests.UnitTests": [[20, 2, 1, "", "__iter__"], [20, 2, 1, "", "evaluate_responses"], [20, 2, 1, "", "execute"], [20, 4, 1, "", "file"], [20, 2, 1, "", "generate_tests"], [20, 2, 1, "", "get_evaluation_result_as_numpy"], [20, 4, 1, "", "metadata"], [20, 4, 1, "", "metrics"], [20, 2, 1, "", "paraphrase"], [20, 2, 1, "", "read_file"], [20, 2, 1, "", "tests"], [20, 4, 1, "", "unit_tests"]], "unit_tests_result": [[21, 1, 1, "", "AtomicTestCaseExecutionResult"], [21, 1, 1, "", "ExecutionResult"], [21, 1, 1, "", "ParaphrasedQuestion"]], "unit_tests_result.AtomicTestCaseExecutionResult": [[21, 4, 1, "", "passed"], [21, 4, 1, "", "reason"], [21, 4, 1, "", "test_case"]], "unit_tests_result.ExecutionResult": [[21, 4, 1, "", "answer"], [21, 2, 1, "", "evaluate_responses"], [21, 2, 1, "", "get_evaluation_result_as_numpy"], [21, 4, 1, "", "test_cases"]], "unit_tests_result.ParaphrasedQuestion": [[21, 2, 1, "", "evaluate_responses"], [21, 2, 1, "", "execute"], [21, 4, 1, "", "execution_result"], [21, 2, 1, "", "get_evaluation_result_as_numpy"], [21, 4, 1, "", "question"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "data", "Python data"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:data", "4": "py:attribute", "5": "py:function"}, "terms": {"0": 1, "1": 2, "For": 1, "It": 0, "The": 22, "To": 22, "With": 22, "_": 22, "__iter__": 20, "accuraci": [2, 15, 22], "add": 22, "against": 22, "also": 0, "an": 0, "analysi": 22, "answer": [1, 4, 9, 21], "api_nam": 1, "assess": 22, "async": 4, "atomictestcaseexecutionresult": 21, "atomicunittest": 20, "attribut": 0, "auto": 2, "autoapi": 2, "automat": 0, "b": 22, "back": 0, "base": [1, 3, 11, 12, 13, 14, 16, 18, 20, 21, 22], "base_metr": [2, 11, 13, 14, 15, 16, 20], "base_view": [2, 18, 19], "basemetr": [11, 12, 13, 14, 16, 20], "basetest": [0, 3, 12, 20, 21], "baseview": [17, 18], "befor": 22, "better": 22, "bool": 21, "branch": 22, "break": 22, "build": 22, "calcul": 22, "call_llm_api": 1, "can": 22, "cd": 22, "chang": 22, "checkout": 22, "choic": 1, "classmethod": 0, "client": 4, "clone": 22, "code": 22, "com": 22, "command": 22, "commit": 22, "common_interfac": [2, 3, 12, 20, 21, 22], "comprehens": 22, "config": [1, 22], "config_fil": 1, "configur": 22, "contain": 2, "convert": 0, "creat": [0, 2, 22], "data": 0, "deep_format": 1, "depend": 22, "descript": 3, "design": 22, "detail": 22, "dict": [4, 8], "dictionari": 0, "directori": 22, "do": 22, "document": 2, "dotenv": 22, "easili": [0, 22], "env": 22, "environ": 22, "evalu": 22, "evaluate_answer_for_test": 9, "evaluate_respons": [20, 21], "evaluate_test_cas": 4, "exampl": [1, 22], "execut": [20, 21, 22], "execute_endpoint": 4, "execute_test": [2, 10, 22], "execution_result": 21, "executionresult": 21, "executor": 1, "extract": 1, "extract_answ": 1, "field": 22, "file": [5, 20, 22], "fill": 22, "follow": 22, "fork": 22, "format": 1, "framework": 22, "from": [0, 1], "from_dict": 0, "from_json": 0, "full": 22, "full_pipelin": [2, 10, 22], "function": 22, "gener": 2, "general_stat": [2, 15], "generalstat": 13, "generate_test": 20, "generate_unit_test": 20, "get": 22, "get_evaluation_result_as_numpi": [20, 21], "get_metric_valu": [11, 13, 14, 16], "git": 22, "github": 22, "guidelin": [20, 22], "hallucin": 22, "hallucination_r": [2, 15], "hallucinationr": 14, "help": 0, "helper": [2, 10, 22], "http": 22, "i": 22, "incorrect_respons": [2, 19], "incorrectrespons": 18, "index": 1, "instanti": 0, "instruct": 22, "its": 0, "json": [0, 1, 18], "json_input": 0, "kei": 1, "kwarg": 1, "languag": 22, "librari": 22, "licens": 22, "list": [1, 4, 20, 21], "llm_drift_rat": [2, 15], "llm_executor": [20, 21], "llmdriftrat": 16, "llmexecutor": 1, "load_config": 1, "m": 22, "make": 22, "messag": 1, "metadata": [2, 20, 22], "metric": [2, 10, 20, 22], "metric_nam": [11, 12, 13, 14, 16], "metric_result": [11, 12, 13, 14, 16], "metric_result_question_test_wis": 11, "metric_result_question_wis": 11, "model": [3, 12, 18, 20, 21, 22], "modul": 22, "more": 22, "n": 8, "name": 3, "natur": 22, "necessari": 22, "nest": 1, "new": 22, "nlp": 22, "none": [1, 11, 12, 13, 14, 16, 20], "numpi": 22, "obj": 1, "object": 0, "open": 22, "openai": 22, "openai_cli": [2, 6], "origin": 22, "original_quest": [4, 8], "our": 22, "page": 2, "panda": 22, "paraphras": 20, "paraphrase_help": [2, 6], "paraphrase_quest": [4, 8], "paraphrased_quest": 20, "paraphrasedquest": [20, 21], "pars": 1, "parse_response_path": 1, "particularli": 22, "pass": [11, 12, 13, 14, 16, 21], "path": 1, "path_str": 1, "perform": 22, "pip": 22, "pipelin": 22, "pleas": 22, "process": 22, "project": 22, "provid": 22, "pull": 22, "push": 22, "py": 22, "pydant": 22, "python": 22, "pyyaml": 22, "qualiti": 22, "question": [1, 20, 21], "question_item": 4, "questionitem": 4, "r": 22, "rate": 22, "read_fil": 20, "reason": 21, "recurs": 1, "refer": 22, "relat": 22, "repositori": 22, "request": 22, "requir": 22, "respons": 1, "response_json": 1, "response_path": 1, "restructuredtext": 22, "result": [18, 22], "result_arrai": [11, 13, 14, 16], "rigor": 22, "run": 22, "run_bi": 3, "run_dat": 3, "run_dur": 3, "run_pipelin": 5, "run_tim": 3, "script": 22, "see": 22, "set": 22, "some": 22, "sourc": [2, 3, 20, 21, 22], "sphinx": 2, "start": 22, "step": 22, "store": 0, "str": [4, 8, 9, 20, 21], "string": [0, 1], "structur": 1, "sub": 0, "suit": 22, "syntax": 22, "test": [4, 9, 20, 21], "test_cas": [20, 21], "testcase_evalu": [2, 6], "testcaseresult": 4, "them": 22, "thi": [0, 2, 22], "those": 0, "threshold": [11, 12, 13, 14, 16], "through": 22, "to_dict": 0, "to_json": 0, "tool": 22, "toolset": 22, "transform": 0, "txt": 22, "unit_test": [2, 18, 22], "unit_tests_result": [2, 20, 22], "unittest": [18, 20], "us": 22, "user": 22, "uuid": 3, "uuid_val": 3, "variabl": 22, "variou": 22, "view": [2, 10, 22], "visual": 22, "we": 22, "welcom": 22, "yaml": [1, 22], "you": 22, "yourfeatur": 22, "yourusernam": 22}, "titles": ["common_interface", "execute_tests", "API Reference", "metadata", "sources.execute_tests", "sources.full_pipeline", "sources.helpers", "sources.helpers.openai_client", "sources.helpers.paraphrase_helper", "sources.helpers.testcase_evaluator", "sources", "sources.metrics.accuracy", "sources.metrics.base_metric", "sources.metrics.general_stats", "sources.metrics.hallucination_rate", "sources.metrics", "sources.metrics.llm_drift_rate", "sources.views.base_view", "sources.views.incorrect_responses", "sources.views", "unit_tests", "unit_tests_result", "BreakYourLLM documentation"], "titleterms": {"accuraci": 11, "api": [2, 22], "attribut": [1, 4, 7, 20], "base_metr": 12, "base_view": 17, "breakyourllm": 22, "class": [0, 1, 3, 11, 12, 13, 14, 16, 17, 18, 20, 21], "codebas": 22, "common_interfac": 0, "content": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22], "contribut": 22, "document": 22, "execute_test": [1, 4], "featur": 22, "full_pipelin": 5, "function": [4, 5, 8, 9], "general_stat": 13, "hallucination_r": 14, "helper": [6, 7, 8, 9], "incorrect_respons": 18, "instal": 22, "llm": 22, "llm_drift_rat": 16, "metadata": 3, "metric": [11, 12, 13, 14, 15, 16], "modul": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 20, 21], "openai_cli": 7, "organ": 22, "overview": 22, "paraphrase_help": 8, "product": 22, "refer": 2, "simul": 22, "sourc": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "submodul": [6, 10, 15, 19], "tabl": 22, "technologi": 22, "test": 22, "testcase_evalu": 9, "unit_test": 20, "unit_tests_result": 21, "usag": 22, "view": [17, 18, 19], "your": 22}})